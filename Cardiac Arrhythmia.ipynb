{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columns_list=list(range(1,281))\n",
    "columns_list\n",
    "data = pd.read_csv('cardiac_arrhythmia.csv',header=None,names=columns_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1    2    3    4    5    6    7    8    9    10  ...   271   272  273  274  \\\n",
       "0   75    0  190   80   91  193  371  174  121  -16 ...   0.0   9.0 -0.9  0.0   \n",
       "1   56    1  165   64   81  174  401  149   39   25 ...   0.0   8.5  0.0  0.0   \n",
       "2   54    0  172   95  138  163  386  185  102   96 ...   0.0   9.5 -2.4  0.0   \n",
       "3   55    0  175   94  100  202  380  179  143   28 ...   0.0  12.2 -2.2  0.0   \n",
       "4   75    0  190   80   88  181  360  177  103  -16 ...   0.0  13.1 -3.6  0.0   \n",
       "\n",
       "  275  276  277   278   279  280  \n",
       "0   0  0.9  2.9  23.3  49.4    8  \n",
       "1   0  0.2  2.1  20.4  38.8    6  \n",
       "2   0  0.3  3.4  12.3  49.0   10  \n",
       "3   0  0.4  2.6  34.6  61.6    1  \n",
       "4   0 -0.1  3.9  25.4  62.8    7  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 280)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.0</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.471239</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>166.188053</td>\n",
       "      <td>68.170354</td>\n",
       "      <td>88.920354</td>\n",
       "      <td>155.152655</td>\n",
       "      <td>367.207965</td>\n",
       "      <td>169.949115</td>\n",
       "      <td>90.004425</td>\n",
       "      <td>33.676991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278982</td>\n",
       "      <td>9.048009</td>\n",
       "      <td>-1.457301</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514823</td>\n",
       "      <td>1.222345</td>\n",
       "      <td>19.326106</td>\n",
       "      <td>29.473230</td>\n",
       "      <td>3.880531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.466631</td>\n",
       "      <td>0.497955</td>\n",
       "      <td>37.170340</td>\n",
       "      <td>16.590803</td>\n",
       "      <td>15.364394</td>\n",
       "      <td>44.842283</td>\n",
       "      <td>33.385421</td>\n",
       "      <td>35.633072</td>\n",
       "      <td>25.826643</td>\n",
       "      <td>45.431434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548876</td>\n",
       "      <td>3.472862</td>\n",
       "      <td>2.002430</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347531</td>\n",
       "      <td>1.426052</td>\n",
       "      <td>13.503922</td>\n",
       "      <td>18.493927</td>\n",
       "      <td>4.407097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-44.200000</td>\n",
       "      <td>-38.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>17.550000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>25.825000</td>\n",
       "      <td>41.125000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>88.800000</td>\n",
       "      <td>115.900000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1           2           3           4           5           6    \\\n",
       "count  452.000000  452.000000  452.000000  452.000000  452.000000  452.000000   \n",
       "mean    46.471239    0.550885  166.188053   68.170354   88.920354  155.152655   \n",
       "std     16.466631    0.497955   37.170340   16.590803   15.364394   44.842283   \n",
       "min      0.000000    0.000000  105.000000    6.000000   55.000000    0.000000   \n",
       "25%     36.000000    0.000000  160.000000   59.000000   80.000000  142.000000   \n",
       "50%     47.000000    1.000000  164.000000   68.000000   86.000000  157.000000   \n",
       "75%     58.000000    1.000000  170.000000   79.000000   94.000000  175.000000   \n",
       "max     83.000000    1.000000  780.000000  176.000000  188.000000  524.000000   \n",
       "\n",
       "              7           8           9           10      ...             271  \\\n",
       "count  452.000000  452.000000  452.000000  452.000000     ...      452.000000   \n",
       "mean   367.207965  169.949115   90.004425   33.676991     ...       -0.278982   \n",
       "std     33.385421   35.633072   25.826643   45.431434     ...        0.548876   \n",
       "min    232.000000  108.000000    0.000000 -172.000000     ...       -4.100000   \n",
       "25%    350.000000  148.000000   79.000000    3.750000     ...       -0.425000   \n",
       "50%    367.000000  162.000000   91.000000   40.000000     ...        0.000000   \n",
       "75%    384.000000  179.000000  102.000000   66.000000     ...        0.000000   \n",
       "max    509.000000  381.000000  205.000000  169.000000     ...        0.000000   \n",
       "\n",
       "              272         273         274    275         276         277  \\\n",
       "count  452.000000  452.000000  452.000000  452.0  452.000000  452.000000   \n",
       "mean     9.048009   -1.457301    0.003982    0.0    0.514823    1.222345   \n",
       "std      3.472862    2.002430    0.050118    0.0    0.347531    1.426052   \n",
       "min      0.000000  -28.600000    0.000000    0.0   -0.800000   -6.000000   \n",
       "25%      6.600000   -2.100000    0.000000    0.0    0.400000    0.500000   \n",
       "50%      8.800000   -1.100000    0.000000    0.0    0.500000    1.350000   \n",
       "75%     11.200000    0.000000    0.000000    0.0    0.700000    2.100000   \n",
       "max     23.600000    0.000000    0.800000    0.0    2.400000    6.000000   \n",
       "\n",
       "              278         279         280  \n",
       "count  452.000000  452.000000  452.000000  \n",
       "mean    19.326106   29.473230    3.880531  \n",
       "std     13.503922   18.493927    4.407097  \n",
       "min    -44.200000  -38.600000    1.000000  \n",
       "25%     11.450000   17.550000    1.000000  \n",
       "50%     18.100000   27.900000    1.000000  \n",
       "75%     25.825000   41.125000    6.000000  \n",
       "max     88.800000  115.900000   16.000000  \n",
       "\n",
       "[8 rows x 275 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 452 entries, 0 to 451\n",
      "Columns: 280 entries, 1 to 280\n",
      "dtypes: float64(116), int64(159), object(5)\n",
      "memory usage: 988.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>171</td>\n",
       "      <td>102</td>\n",
       "      <td>135</td>\n",
       "      <td>70</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>?</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>376</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         11   12   13   14   15\n",
       "count   452  452  452  452  452\n",
       "unique  171  102  135   70   64\n",
       "top      52   60   59    ?   72\n",
       "freq     13   23    9  376   21"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_data=data.select_dtypes(include=['object'], exclude=['float64','int64'])\n",
    "object_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>444</td>\n",
       "      <td>430</td>\n",
       "      <td>451</td>\n",
       "      <td>76</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>170</td>\n",
       "      <td>101</td>\n",
       "      <td>134</td>\n",
       "      <td>69</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         11   12   13  14   15\n",
       "count   444  430  451  76  451\n",
       "unique  170  101  134  69   63\n",
       "top      52   60   59  84   72\n",
       "freq     13   23    9   3   21"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing '?' with NAn\n",
    "#data=data.replace(to_replace='?', value=np.nan, inplace=False, limit=None, regex=False, method='pad', axis=None)\n",
    "data=data.replace('?', np.NaN)\n",
    "object_data=data.select_dtypes(include=['object'], exclude=['float64','int64'])\n",
    "object_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6208d269f320>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 452 entries, 0 to 451\n",
      "Columns: 280 entries, 11 to 280\n",
      "dtypes: float64(121), int64(159)\n",
      "memory usage: 988.8 KB\n"
     ]
    }
   ],
   "source": [
    "# changing datatype to float from object\n",
    "data_object=data.select_dtypes(include=['object'], exclude=['float64','int64']).astype(float)\n",
    "data_float=data.select_dtypes(include=['float64','int64'], exclude=['object'])\n",
    "data_new=pd.concat([data_object,data_float],axis = 1)\n",
    "data_new.info()\n",
    "#Converted all columns of datatypes into float (total - 116+5=121 float columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 11,  12,  13,  14,  15,   1,   2,   3,   4,   5,\n",
       "            ...\n",
       "            271, 272, 273, 274, 275, 276, 277, 278, 279, 280],\n",
       "           dtype='int64', length=280)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 452 entries, 0 to 451\n",
      "Columns: 280 entries, 1 to 280\n",
      "dtypes: float64(280)\n",
      "memory usage: 988.8 KB\n"
     ]
    }
   ],
   "source": [
    "data_numeric=data.astype(float)\n",
    "data_numeric.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/452 with 1 missing, elapsed time: 0.309\n",
      "Imputing row 101/452 with 1 missing, elapsed time: 0.312\n",
      "Imputing row 201/452 with 2 missing, elapsed time: 0.315\n",
      "Imputing row 301/452 with 1 missing, elapsed time: 0.317\n",
      "Imputing row 401/452 with 1 missing, elapsed time: 0.319\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1    2      3     4      5      6      7      8      9     10   ...   271  \\\n",
       "0  75.0  0.0  190.0  80.0   91.0  193.0  371.0  174.0  121.0 -16.0  ...   0.0   \n",
       "1  56.0  1.0  165.0  64.0   81.0  174.0  401.0  149.0   39.0  25.0  ...   0.0   \n",
       "2  54.0  0.0  172.0  95.0  138.0  163.0  386.0  185.0  102.0  96.0  ...   0.0   \n",
       "3  55.0  0.0  175.0  94.0  100.0  202.0  380.0  179.0  143.0  28.0  ...   0.0   \n",
       "4  75.0  0.0  190.0  80.0   88.0  181.0  360.0  177.0  103.0 -16.0  ...   0.0   \n",
       "\n",
       "    272  273  274  275  276  277   278   279   280  \n",
       "0   9.0 -0.9  0.0  0.0  0.9  2.9  23.3  49.4   8.0  \n",
       "1   8.5  0.0  0.0  0.0  0.2  2.1  20.4  38.8   6.0  \n",
       "2   9.5 -2.4  0.0  0.0  0.3  3.4  12.3  49.0  10.0  \n",
       "3  12.2 -2.2  0.0  0.0  0.4  2.6  34.6  61.6   1.0  \n",
       "4  13.1 -3.6  0.0  0.0 -0.1  3.9  25.4  62.8   7.0  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imputation\n",
    "from fancyimpute import KNN\n",
    "\n",
    "data_numeric=data_numeric.select_dtypes(include=[np.float])\n",
    "data_filled=pd.DataFrame(KNN(3).complete(data_numeric))\n",
    "\n",
    "data_filled.columns = data_numeric.columns\n",
    "data_filled.index = data_numeric.index\n",
    "data_filled.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Train Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=data_filled.drop(280,axis=1)\n",
    "y=data_filled[280]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0, test_size=0.2)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scaling Data USing MinMax scaler:\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "#test=test.select_dtypes(include=[np.float])\n",
    "X_train=scaler.fit_transform(X)\n",
    "# The same instance of the transformer can then be applied to some new test data unseen during the fit call: the same scaling and shifting operations will be applied to be consistent with the transformation performed on the train data\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False], dtype=bool)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_count=data_filled.isnull().sum(axis=0)>0\n",
    "list_count.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##KNN \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': [2,3,4,5,6,7,8,9,10]}\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 5}\n",
      "Best cross-validation score: 0.62\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "mean_test_score=grid_search.cv_results_[\"mean_test_score\"]\n",
    "k=[2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.66\n",
      "Test score: 0.54\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= 5)\n",
    "knn.fit(X_train,y_train)\n",
    "y_knn = knn.predict(X_test)\n",
    "print('Train score: {0:0.2f}'.format(knn.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x206ef70a048>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD3CAYAAADxJYRbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBL5/1nl6MtW3HBEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x206ef680780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot between number of neighbours and test scores\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline \n",
    "\n",
    "plt.plot(k,mean_test_score,\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.64\n",
      "Test score: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Bagging for KNN mmodel\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors= 5)\n",
    "\n",
    "bagging_clf = BaggingClassifier(knn, n_estimators = 100, max_samples=0.66,max_features = 50, bootstrap = True)\n",
    "X=scaler.fit_transform(X)\n",
    "bagging_clf.fit(X_train,y_train)\n",
    "print('Train score: {0:0.2f}'.format(bagging_clf.score(X_train,y_train)))\n",
    "print('Test score: {0:0.2f}'.format(bagging_clf.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [ 0.56410256  0.62162162  0.59722222  0.69565217  0.64705882]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62513148107777261"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train multinomial logistic regression model\n",
    "\n",
    "mul_lr = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "#Multinomial supports only l2 norm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mul_lr, X_train,y_train, cv = 5)\n",
    "print(\"Cross validation scores: {}\".format(scores))\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mul_lr = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "mul_lr.fit(X_train,y_train)\n",
    "y_mul_lr = mul_lr.predict(X_test)\n",
    "print('Train score: {0:0.2f}'.format(mul_lr.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(mul_lr.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'penalty': 'l1'}\n",
      "Best cross-validation score: 0.65\n",
      "Train score: 1.00\n",
      "Test score: 0.59\n"
     ]
    }
   ],
   "source": [
    "#since the test score is very low lets try with normal logistic regression\n",
    "mul_lr = LogisticRegression()\n",
    "param_grid = {'penalty':['l1', 'l2']}\n",
    "grid_search = GridSearchCV(mul_lr , param_grid, cv = 10 , return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "mul_lr=LogisticRegression(penalty='l1')\n",
    "mul_lr.fit(X_train,y_train)\n",
    "y_mul_lr = mul_lr.predict(X_test)\n",
    "print('Train score: {0:0.2f}'.format(mul_lr.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(mul_lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using adaboost will not help as train score is already 1. Boosting will not help to increase the test  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  3  0  0  0  5  0  0  6  0  0  1]\n",
      " [ 4  3  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  3  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  2  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  0  0  0  0  0  7  0  0  2]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  1  0  0  2  0  0  0  0  1  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,y_mul_lr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.81      0.69      0.75        49\n",
      "        2.0       0.27      0.38      0.32         8\n",
      "        3.0       0.60      0.60      0.60         5\n",
      "        4.0       0.67      1.00      0.80         2\n",
      "        5.0       0.67      0.67      0.67         3\n",
      "        6.0       0.22      0.50      0.31         4\n",
      "        7.0       0.00      0.00      0.00         1\n",
      "        9.0       0.00      0.00      0.00         1\n",
      "       10.0       0.54      0.64      0.58        11\n",
      "       14.0       0.00      0.00      0.00         1\n",
      "       15.0       0.00      0.00      0.00         0\n",
      "       16.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.60      0.58      0.59        91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_mul_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.80\n",
      "Test score: 0.62\n",
      "out of bag score: 0.05\n"
     ]
    }
   ],
   "source": [
    "#Bagging\n",
    "mul_lr=LogisticRegression(penalty='l1')\n",
    "bagging_clf = BaggingClassifier(mul_lr,n_estimators=50, max_samples=0.66, max_features = 50, bootstrap = True,oob_score=True)\n",
    "X=scaler.fit_transform(X)\n",
    "bagging_clf.fit(X_train,y_train)\n",
    "print('Train score: {0:0.2f}'.format(bagging_clf.score(X_train,y_train)))\n",
    "print('Test score: {0:0.2f}'.format(bagging_clf.score(X_test,y_test)))\n",
    "print('out of bag score: {0:0.2f}'.format(bagging_clf.oob_score_))\n",
    "# We get very low accuracy when we test data on very few observations since we have fifteen classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 10, 100, 1000, 10000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVC Support Vector Classifiers:\n",
    "\n",
    "svc=LinearSVC()\n",
    "param_grid={\"C\" : [1,10,100,1000,10000]}\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1000}\n",
      "Best cross-validation score: 0.67\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [500, 750, 1000, 1500, 2000, 2500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Further fine tuning the parameter to check for the best fit\n",
    "param_grid={\"C\" : [500,750,1000,1500,2000,2500]}\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1500}\n",
      "Best cross-validation score: 0.68\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.98\n",
      "Test score: 0.57\n"
     ]
    }
   ],
   "source": [
    "svc=LinearSVC(C= 1500 )\n",
    "svc.fit(X_train,y_train)\n",
    "y_svc_linear=svc.predict(X_test)\n",
    "print('Train score: {0:0.2f}'.format(svc.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using adaboost will not help as train score is almost 1. Boosting will not help to incraese the test  accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.79\n",
      "Test score: 0.68\n"
     ]
    }
   ],
   "source": [
    "#Bagging\n",
    "svc_linear=LinearSVC(C= 1500 )\n",
    "bagging_clf = BaggingClassifier(svc_linear,n_estimators=50, max_samples=0.66, max_features = 50, bootstrap = True,oob_score=True)\n",
    "X=scaler.fit_transform(X)\n",
    "bagging_clf.fit(X_train,y_train)\n",
    "print('Train score: {0:0.2f}'.format(bagging_clf.score(X_train,y_train)))\n",
    "print('Test score: {0:0.2f}'.format(bagging_clf.score(X_test,y_test)))\n",
    "#print('out of bag score: {0:0.2f}'.format(bagging_clf.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.01, 0.1, 1, 10, 100], 'C': [1, 10, 100, 1000, 10000], 'degree': [2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kerneralized SVCs, changing the kernel to 'poly' and 'rbf'\n",
    "svc=SVC(kernel='poly')\n",
    "param_grid={\"gamma\" : [0.01,0.1,1,10,100],\"C\" : [1,10,100,1000,10000],\"degree\" : [2,3]}\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'degree': 2, 'gamma': 0.01}\n",
      "Best cross-validation score: 0.68\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.01, 0.001, 0.005, 0.0005], 'C': [0.5, 1, 1.5, 2, 0.75], 'degree': [2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Further fine tuning the parameter to check for the best fit\n",
    "svc=SVC(kernel='poly')\n",
    "param_grid={\"gamma\" : [0.01,0.001,0.005,0.0005],\"C\" : [0.5,1,1.5,2,0.75],\"degree\" : [2,3]}\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.5, 'degree': 2, 'gamma': 0.01}\n",
      "Best cross-validation score: 0.68\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.65\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(kernel='poly',C= 0.5 , degree=2 , gamma= 0.01)\n",
    "svc.fit(X_train,y_train)\n",
    "y_svc_poly=svc.predict(X_test)\n",
    "print('Train score: {0:0.2f}'.format(svc.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.91\n",
      "Test score: 0.62\n"
     ]
    }
   ],
   "source": [
    "#Bagging\n",
    "svc_poly=SVC(kernel='poly',C= 0.5 , degree=2 , gamma= 0.01)\n",
    "bagging_clf = BaggingClassifier(svc_poly,n_estimators=50, max_samples=0.66, max_features = 50, bootstrap = True,oob_score=True)\n",
    "bagging_clf.fit(X_train,y_train)\n",
    "print('Train score: {0:0.2f}'.format(bagging_clf.score(X_train,y_train)))\n",
    "print('Test score: {0:0.2f}'.format(bagging_clf.score(X_test,y_test)))\n",
    "#print('out of bag score: {0:0.2f}'.format(bagging_clf.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.01, 0.001, 0.005, 0.0005], 'C': [0.5, 1, 1.5, 2, 0.75], 'degree': [2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=SVC(kernel='rbf')\n",
    "param_grid={\"gamma\" : [0.01,0.001,0.005,0.0005],\"C\" : [0.5,1,1.5,2,0.75],\"degree\" : [2,3]}\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.5, 'degree': 2, 'gamma': 0.01}\n",
      "Best cross-validation score: 0.54\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.54\n",
      "Test score: 0.54\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(kernel='rbf',C= 0.5 , degree=2 , gamma= 0.01)\n",
    "svc.fit(X_train,y_train)\n",
    "y_svc_rbf=svc.predict(X_test)\n",
    "print('Train score: {0:0.2f}'.format(svc.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.54\n",
      "Test score: 0.54\n",
      "out of bag score: 0.10\n"
     ]
    }
   ],
   "source": [
    "#Bagging\n",
    "svc_rbf=SVC(kernel='rbf',C= 0.5 , degree=2 , gamma= 0.01)\n",
    "bagging_clf = BaggingClassifier(svc_rbf,n_estimators=50, max_samples=0.66, max_features = 50, bootstrap = True,oob_score=True)\n",
    "X=scaler.fit_transform(X)\n",
    "bagging_clf.fit(X_train,y_train)\n",
    "print('Train score: {0:0.2f}'.format(bagging_clf.score(X_train,y_train)))\n",
    "print('Test score: {0:0.2f}'.format(bagging_clf.score(X_test,y_test)))\n",
    "print('out of bag score: {0:0.2f}'.format(bagging_clf.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.54\n",
      "Test score: 0.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier(base_estimator = svc_rbf, learning_rate = 0.5, algorithm='SAMME')\n",
    "adaboost_clf.fit(X_train,y_train)\n",
    "\n",
    "print('Train score: {0:0.2f}'.format(adaboost_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(adaboost_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [5, 10, 20, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "param_grid = {'max_depth': [5, 10, 20, 50, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(dt_clf, param_grid, cv = 10, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 5}\n",
      "Best cross-validation score: 0.70\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.81\n",
      "Test score: 0.07\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth = 5)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "#y_dt_clf = dt_clf.predict(X_test)\n",
    "print('Train score: {0:0.2f}'.format(dt_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(dt_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.54\n"
     ]
    }
   ],
   "source": [
    "#ada boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier(base_estimator = dt_clf, learning_rate = 0.5)\n",
    "adaboost_clf.fit(X_train,y_train)\n",
    "\n",
    "print('Train score: {0:0.2f}'.format(adaboost_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(adaboost_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "param_grid = {'max_depth': [5, 10, 20, 50, 100], 'max_features': [20,40,60,80,100,150,50],'learning_rate': [0.1]}\n",
    "grid_search = GridSearchCV(gb_clf, param_grid, cv = 10, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Train score: {0:0.2f}'.format(gb_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(gb_clf.score(X_test, y_test)))\n",
    "print('Feature Importance: '.format(gb_clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state = 0, max_depth=20, max_features=80, learning_rate=)\n",
    "gb_clf.fit(X_train,y_train)\n",
    "\n",
    "print('Train score: {0:0.2f}'.format(gb_clf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(gb_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RF classifier on training set: 0.98\n",
      "Accuracy of RF classifier on test set: 0.66\n"
     ]
    }
   ],
   "source": [
    "#RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Rf = RandomForestClassifier(random_state = 0)\n",
    "param_grid = {'max_depth': [5, 10, 20, 50, 100], 'max_features': [20,40,60,80,100,150,50]}\n",
    "grid_search = GridSearchCV(Rf, param_grid, cv = 10, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Accuracy of RF classifier on training set: {:.2f}'\n",
    "     .format(grid_search.score(X_train, y_train)))\n",
    "print('Accuracy of RF classifier on test set: {:.2f}'\n",
    "     .format(grid_search.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'max_features': 80}\n",
      "Best cross-validation score: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.98\n",
      "Test score: 0.66\n"
     ]
    }
   ],
   "source": [
    "Rf = RandomForestClassifier(random_state = 0, max_depth=20, max_features=80)\n",
    "Rf.fit(X_train,y_train)\n",
    "\n",
    "print('Train score: {0:0.2f}'.format(Rf.score(X_train, y_train)))\n",
    "print('Test score: {0:0.2f}'.format(Rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA : Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314581</td>\n",
       "      <td>0.599912</td>\n",
       "      <td>0.071713</td>\n",
       "      <td>-0.369022</td>\n",
       "      <td>-0.283923</td>\n",
       "      <td>-0.634363</td>\n",
       "      <td>0.429417</td>\n",
       "      <td>0.345233</td>\n",
       "      <td>-0.153416</td>\n",
       "      <td>0.360345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027521</td>\n",
       "      <td>0.029820</td>\n",
       "      <td>0.072755</td>\n",
       "      <td>0.031541</td>\n",
       "      <td>-0.018982</td>\n",
       "      <td>-0.008006</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0.041170</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>-0.031657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.851578</td>\n",
       "      <td>-0.800850</td>\n",
       "      <td>-0.384635</td>\n",
       "      <td>-0.320565</td>\n",
       "      <td>0.402787</td>\n",
       "      <td>0.292741</td>\n",
       "      <td>0.329512</td>\n",
       "      <td>-0.032229</td>\n",
       "      <td>0.127883</td>\n",
       "      <td>-0.093934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036328</td>\n",
       "      <td>-0.051208</td>\n",
       "      <td>-0.032580</td>\n",
       "      <td>-0.000662</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.024265</td>\n",
       "      <td>0.034680</td>\n",
       "      <td>-0.034350</td>\n",
       "      <td>-0.032127</td>\n",
       "      <td>0.066729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.100024</td>\n",
       "      <td>1.032176</td>\n",
       "      <td>0.103204</td>\n",
       "      <td>0.247589</td>\n",
       "      <td>0.377259</td>\n",
       "      <td>0.168628</td>\n",
       "      <td>0.230955</td>\n",
       "      <td>0.693831</td>\n",
       "      <td>0.207992</td>\n",
       "      <td>-0.142524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075161</td>\n",
       "      <td>-0.076542</td>\n",
       "      <td>-0.064789</td>\n",
       "      <td>-0.054888</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>-0.019883</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>-0.009686</td>\n",
       "      <td>-0.010840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781607</td>\n",
       "      <td>-0.714912</td>\n",
       "      <td>0.027404</td>\n",
       "      <td>0.183441</td>\n",
       "      <td>-1.081315</td>\n",
       "      <td>0.219100</td>\n",
       "      <td>0.513715</td>\n",
       "      <td>0.338891</td>\n",
       "      <td>0.225024</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018853</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0.050973</td>\n",
       "      <td>-0.091333</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>-0.011731</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>-0.037700</td>\n",
       "      <td>-0.021884</td>\n",
       "      <td>0.012123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.495370</td>\n",
       "      <td>0.219858</td>\n",
       "      <td>0.126741</td>\n",
       "      <td>-0.081379</td>\n",
       "      <td>0.354040</td>\n",
       "      <td>0.244107</td>\n",
       "      <td>0.331437</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>0.034898</td>\n",
       "      <td>-0.255759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.027183</td>\n",
       "      <td>-0.032218</td>\n",
       "      <td>-0.047929</td>\n",
       "      <td>-0.017104</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>-0.079556</td>\n",
       "      <td>-0.063369</td>\n",
       "      <td>-0.007343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.314581  0.599912  0.071713 -0.369022 -0.283923 -0.634363  0.429417   \n",
       "1 -0.851578 -0.800850 -0.384635 -0.320565  0.402787  0.292741  0.329512   \n",
       "2 -1.100024  1.032176  0.103204  0.247589  0.377259  0.168628  0.230955   \n",
       "3  0.781607 -0.714912  0.027404  0.183441 -1.081315  0.219100  0.513715   \n",
       "4  1.495370  0.219858  0.126741 -0.081379  0.354040  0.244107  0.331437   \n",
       "\n",
       "        7         8         9      ...          126       127       128  \\\n",
       "0  0.345233 -0.153416  0.360345    ...    -0.027521  0.029820  0.072755   \n",
       "1 -0.032229  0.127883 -0.093934    ...    -0.036328 -0.051208 -0.032580   \n",
       "2  0.693831  0.207992 -0.142524    ...    -0.075161 -0.076542 -0.064789   \n",
       "3  0.338891  0.225024  0.007782    ...     0.018853  0.070833  0.050973   \n",
       "4  0.017272  0.034898 -0.255759    ...     0.012940  0.027183 -0.032218   \n",
       "\n",
       "        129       130       131       132       133       134       135  \n",
       "0  0.031541 -0.018982 -0.008006 -0.007219  0.041170  0.013073 -0.031657  \n",
       "1 -0.000662  0.005448  0.024265  0.034680 -0.034350 -0.032127  0.066729  \n",
       "2 -0.054888  0.018476 -0.019883  0.002653  0.004320 -0.009686 -0.010840  \n",
       "3 -0.091333  0.016360 -0.011731  0.009839 -0.037700 -0.021884  0.012123  \n",
       "4 -0.047929 -0.017104  0.003462  0.002365 -0.079556 -0.063369 -0.007343  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.99)\n",
    "#need to fit transform the test data in similar way before predicting\n",
    "X2D = pca.fit_transform(X)\n",
    "pca_df=pd.DataFrame(X2D)\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11260916,  0.09346734,  0.0679447 ,  0.05913164,  0.05390443,\n",
       "        0.04359193,  0.0375878 ,  0.02798326,  0.02505853,  0.02261404,\n",
       "        0.02090701,  0.01787322,  0.01659478,  0.01463752,  0.01385009,\n",
       "        0.01346132,  0.01192036,  0.0111257 ,  0.01091068,  0.01078706,\n",
       "        0.00991531,  0.00962082,  0.00860658,  0.00841748,  0.0079782 ,\n",
       "        0.00775645,  0.00753626,  0.00734326,  0.00711423,  0.00700624,\n",
       "        0.00688608,  0.00652311,  0.00626414,  0.00600887,  0.00600705,\n",
       "        0.00575083,  0.00554537,  0.00539003,  0.00526787,  0.00506569,\n",
       "        0.00497235,  0.00477321,  0.00474124,  0.00447713,  0.00444032,\n",
       "        0.00415787,  0.00411034,  0.00399913,  0.00389313,  0.00378086,\n",
       "        0.00358059,  0.00341866,  0.00330206,  0.00328737,  0.00319538,\n",
       "        0.00314536,  0.00292526,  0.0028849 ,  0.00287808,  0.0027887 ,\n",
       "        0.00271719,  0.00268982,  0.00255054,  0.00249643,  0.00240406,\n",
       "        0.00233277,  0.00225127,  0.00220889,  0.00217295,  0.00208921,\n",
       "        0.00206752,  0.00199768,  0.00196672,  0.00192786,  0.00185944,\n",
       "        0.00182655,  0.00180767,  0.00175498,  0.00167373,  0.00161609,\n",
       "        0.00158977,  0.00152333,  0.00148672,  0.00142491,  0.00140414,\n",
       "        0.00135675,  0.00132258,  0.00128483,  0.00125933,  0.00121765,\n",
       "        0.00119992,  0.00118975,  0.00115846,  0.00109219,  0.00107657,\n",
       "        0.00104125,  0.00101516,  0.00100808,  0.00098614,  0.00097921,\n",
       "        0.0009557 ,  0.00093124,  0.00089784,  0.00087262,  0.00084244,\n",
       "        0.00081639,  0.00080716,  0.00078541,  0.00076416,  0.00074581,\n",
       "        0.00073964,  0.00071991,  0.00069157,  0.00067968,  0.00065698,\n",
       "        0.00064884,  0.00062367,  0.00060745,  0.00060103,  0.00058185,\n",
       "        0.00057285,  0.00055445,  0.00053824,  0.00053538,  0.00049805,\n",
       "        0.00048781,  0.0004665 ,  0.00045676,  0.00044415,  0.00043922,\n",
       "        0.0004306 ,  0.0004154 ,  0.00040699,  0.00038551,  0.00037556,\n",
       "        0.00036107])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99008239649031571"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total variance explained\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.3,  20.6,  27.4,  33.3,  38.7,  43.1,  46.9,  49.7,  52.2,\n",
       "        54.5,  56.6,  58.4,  60.1,  61.6,  63. ,  64.3,  65.5,  66.6,\n",
       "        67.7,  68.8,  69.8,  70.8,  71.7,  72.5,  73.3,  74.1,  74.9,\n",
       "        75.6,  76.3,  77. ,  77.7,  78.4,  79. ,  79.6,  80.2,  80.8,\n",
       "        81.4,  81.9,  82.4,  82.9,  83.4,  83.9,  84.4,  84.8,  85.2,\n",
       "        85.6,  86. ,  86.4,  86.8,  87.2,  87.6,  87.9,  88.2,  88.5,\n",
       "        88.8,  89.1,  89.4,  89.7,  90. ,  90.3,  90.6,  90.9,  91.2,\n",
       "        91.4,  91.6,  91.8,  92. ,  92.2,  92.4,  92.6,  92.8,  93. ,\n",
       "        93.2,  93.4,  93.6,  93.8,  94. ,  94.2,  94.4,  94.6,  94.8,\n",
       "        95. ,  95.1,  95.2,  95.3,  95.4,  95.5,  95.6,  95.7,  95.8,\n",
       "        95.9,  96. ,  96.1,  96.2,  96.3,  96.4,  96.5,  96.6,  96.7,\n",
       "        96.8,  96.9,  97. ,  97.1,  97.2,  97.3,  97.4,  97.5,  97.6,\n",
       "        97.7,  97.8,  97.9,  98. ,  98.1,  98.2,  98.3,  98.4,  98.5,\n",
       "        98.6,  98.7,  98.8,  98.9,  99. ,  99.1,  99.2,  99.2,  99.2,\n",
       "        99.2,  99.2,  99.2,  99.2,  99.2,  99.2,  99.2,  99.2,  99.2,  99.2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=3)*100)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x206ef046940>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x206eefba860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of Components')\n",
    "plt.title('PCA Analysis')\n",
    "plt.ylim(30,100.5)\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% variance is explained by 80 components whereas to just explain another 5 % variance a total of 140 components are required.\n",
    " \n",
    "Therefore, selecting the first 60 components for building classification model which can explain a total of 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314581</td>\n",
       "      <td>0.599912</td>\n",
       "      <td>0.071713</td>\n",
       "      <td>-0.369022</td>\n",
       "      <td>-0.283923</td>\n",
       "      <td>-0.634363</td>\n",
       "      <td>0.429417</td>\n",
       "      <td>0.345233</td>\n",
       "      <td>-0.153416</td>\n",
       "      <td>0.360345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087038</td>\n",
       "      <td>0.078120</td>\n",
       "      <td>0.040553</td>\n",
       "      <td>0.034618</td>\n",
       "      <td>0.058393</td>\n",
       "      <td>-0.091967</td>\n",
       "      <td>0.071373</td>\n",
       "      <td>-0.168335</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>-0.040082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.851578</td>\n",
       "      <td>-0.800850</td>\n",
       "      <td>-0.384635</td>\n",
       "      <td>-0.320565</td>\n",
       "      <td>0.402787</td>\n",
       "      <td>0.292741</td>\n",
       "      <td>0.329512</td>\n",
       "      <td>-0.032229</td>\n",
       "      <td>0.127883</td>\n",
       "      <td>-0.093934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042464</td>\n",
       "      <td>0.042645</td>\n",
       "      <td>0.037035</td>\n",
       "      <td>-0.013272</td>\n",
       "      <td>0.057427</td>\n",
       "      <td>-0.074813</td>\n",
       "      <td>-0.089975</td>\n",
       "      <td>-0.024229</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>-0.060937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.100024</td>\n",
       "      <td>1.032176</td>\n",
       "      <td>0.103204</td>\n",
       "      <td>0.247589</td>\n",
       "      <td>0.377259</td>\n",
       "      <td>0.168628</td>\n",
       "      <td>0.230955</td>\n",
       "      <td>0.693831</td>\n",
       "      <td>0.207992</td>\n",
       "      <td>-0.142524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470427</td>\n",
       "      <td>-0.112274</td>\n",
       "      <td>-0.010318</td>\n",
       "      <td>0.239513</td>\n",
       "      <td>0.163823</td>\n",
       "      <td>-0.395394</td>\n",
       "      <td>0.033001</td>\n",
       "      <td>-0.461186</td>\n",
       "      <td>0.068252</td>\n",
       "      <td>0.378509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781607</td>\n",
       "      <td>-0.714912</td>\n",
       "      <td>0.027404</td>\n",
       "      <td>0.183441</td>\n",
       "      <td>-1.081315</td>\n",
       "      <td>0.219100</td>\n",
       "      <td>0.513715</td>\n",
       "      <td>0.338891</td>\n",
       "      <td>0.225024</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049648</td>\n",
       "      <td>0.009196</td>\n",
       "      <td>-0.003884</td>\n",
       "      <td>-0.138965</td>\n",
       "      <td>0.058514</td>\n",
       "      <td>-0.033507</td>\n",
       "      <td>-0.027227</td>\n",
       "      <td>-0.024606</td>\n",
       "      <td>-0.025526</td>\n",
       "      <td>-0.212915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.495370</td>\n",
       "      <td>0.219858</td>\n",
       "      <td>0.126741</td>\n",
       "      <td>-0.081379</td>\n",
       "      <td>0.354040</td>\n",
       "      <td>0.244107</td>\n",
       "      <td>0.331437</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>0.034898</td>\n",
       "      <td>-0.255759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133934</td>\n",
       "      <td>-0.096941</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>0.005653</td>\n",
       "      <td>0.056492</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>-0.090120</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.065190</td>\n",
       "      <td>0.055072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.314581  0.599912  0.071713 -0.369022 -0.283923 -0.634363  0.429417   \n",
       "1 -0.851578 -0.800850 -0.384635 -0.320565  0.402787  0.292741  0.329512   \n",
       "2 -1.100024  1.032176  0.103204  0.247589  0.377259  0.168628  0.230955   \n",
       "3  0.781607 -0.714912  0.027404  0.183441 -1.081315  0.219100  0.513715   \n",
       "4  1.495370  0.219858  0.126741 -0.081379  0.354040  0.244107  0.331437   \n",
       "\n",
       "         7         8         9     ...           50        51        52  \\\n",
       "0  0.345233 -0.153416  0.360345    ...    -0.087038  0.078120  0.040553   \n",
       "1 -0.032229  0.127883 -0.093934    ...     0.042464  0.042645  0.037035   \n",
       "2  0.693831  0.207992 -0.142524    ...     0.470427 -0.112274 -0.010318   \n",
       "3  0.338891  0.225024  0.007782    ...     0.049648  0.009196 -0.003884   \n",
       "4  0.017272  0.034898 -0.255759    ...     0.133934 -0.096941  0.034755   \n",
       "\n",
       "         53        54        55        56        57        58        59  \n",
       "0  0.034618  0.058393 -0.091967  0.071373 -0.168335  0.003033 -0.040082  \n",
       "1 -0.013272  0.057427 -0.074813 -0.089975 -0.024229  0.021935 -0.060937  \n",
       "2  0.239513  0.163823 -0.395394  0.033001 -0.461186  0.068252  0.378509  \n",
       "3 -0.138965  0.058514 -0.033507 -0.027227 -0.024606 -0.025526 -0.212915  \n",
       "4  0.005653  0.056492  0.009090 -0.090120  0.001716  0.065190  0.055072  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.90)\n",
    "#need to fit transform the test data in similar way before predicting\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_LDtest = pca.transform(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
